shared:
  upscale: &upscale 4  # 2, 4, 8
  patch_size: &patch_size 128  # 40, 64, 96, 128, 192
  valid_loader: &valid_loader valid

model:
  _key_value: true

  &generator_model generator:
    _target_: esrgan.EncoderDecoderNet
    encoder_params:
      module: esrgan.ESREncoder
      in_channels: &num_channels 3
      out_channels: &latent_channels 64
      num_basic_blocks: 1 # 16
      growth_channels: 32
      activation_fn: &activation_fn
        activation: LeakyReLU
        negative_slope: 0.2
        inplace: true
      residual_scaling: 0.2
    decoder_params:
      module: esrgan.SRResNetDecoder
      in_channels: *latent_channels
      out_channels: *num_channels
      scale_factor: *upscale
      activation_fn: *activation_fn

  &discriminator_model discriminator:
    _target_: esrgan.VGGConv
    encoder_params:
      module: esrgan.StridedConvEncoder
      layer_order: [conv, norm, activation]
      norm_fn: BatchNorm2d
    pooling_params:
      module: AdaptiveAvgPool2d
      output_size: [7, 7]
    head_params:
      module: esrgan.LinearHead
      in_channels: 25088  # 512 * (7x7)
      out_channels: 1
      latent_channels: [1024]
      layer_order: [linear, activation]

args:
  expdir: experiment
  logdir: &logdir ./logs/esrgan_x4_128ps/supervised
  # amp: true

runner:
  _target_: esrgan.GANConfigRunner
  generator_key: *generator_model
  discriminator_key: *discriminator_model

engine:
  _target_: DeviceEngine

# loggers: {}
  # console:
  #   _target_: ConsoleLogger
  # tensorboard:
  #   _target_: TensorboardLogger
  #   logdir: *logdir
  #   use_logdir_postfix: true

stages:
  stage1_supervised:
    num_epochs: 40

    loaders: &loaders
      num_workers: 8
      batch_size: 48

      train_dataset: &train_dataset
        _target_: esrgan.DIV2KDataset
        root: data
        train: true
        target_type: bicubic_X4
        patch_size: [*patch_size, *patch_size]
        transform:
          _target_: albumentations.Compose
          transforms:
            - &spatial_transforms
              _target_: albumentations.Compose
              transforms:
                - transform: albumentations.HorizontalFlip
                  p: 0.5
              additional_targets:
                real_image: image
            - &hard_transforms
              _target_: albumentations.Compose
              transforms:
                - _target_: albumentations.Cutout
                  num_holes: 2
                  max_h_size: 2
                  max_w_size: 2
                - _target_: albumentations.ImageCompression
                  quality_lower: 65
                  p: 0.25
            - &post_transforms
              _target_: albumentations.Compose
              transforms:
                - _target_: albumentations.Normalize
                  mean: 0
                  std: 1
                - _target_: albumentations.ToTensorV2
              additional_targets:
                real_image: image
        low_resolution_image_key: image
        high_resolution_image_key: real_image
        download: false  # TODO: true

      valid_dataset:
        << : [*train_dataset]
        train: false
        transform: *post_transforms

      loaders_params:
        valid:
          batch_size: 1

    criterion:
      _key_value: true

      content_loss:
        _target_: L1Loss  # `L1Loss`, `MSELoss`

    optimizer:
      _key_value: true

      generator_optimizer:
        _target_: Ralamb  # AdamW
        lr_linear_scaling:
          lr: 0.003  # 0.0001
          base_batch_size: &base_batch_size 16
        weight_decay: 0.0
        _model: *generator_model

    scheduler:
      _key_value: true

      generator_scheduler:
        _target_: MultiStepLR
        milestones: [8, 20, 28]
        gamma: 0.5
        _optimizer: generator_optimizer

    callbacks:
      psnr_metric:
        _target_: esrgan.PSNRCallback
        input_key: real_image
        target_key: fake_image
      ssim_metric:
        _target_: esrgan.SSIMCallback
        input_key: real_image
        target_key: fake_image

      loss_content:
        _target_: CriterionCallback
        input_key: real_image
        target_key: fake_image
        metric_key: loss_content
        criterion_key: content_loss

      optimizer_generator:
        _target_: OptimizerCallback
        metric_key: loss_content
        optimizer_key: generator_optimizer
        grad_clip_fn: clip_grad_value_
        grad_clip_params: &grad_clip_params
          clip_value: 5.0

      scheduler_generator:
        _target_: SchedulerCallback
        scheduler_key: generator_scheduler
        loader_key: *valid_loader
        metric_key: loss_content

      # saver:
      #   _target_: CheckpointCallback
      #   logdir: *logdir
      #   loader_key: *valid_loader
      #   metric_key: ssim
      #   minimize: false
      #   use_logdir_postfix: True

      # verbose:
      #   _target_: TqdmCallback

  stage2_gan:
    num_epochs: 16

    loaders:
      << : [*loaders]

      train_dataset:
        << : [*train_dataset]
        transform:
          _target_: albumentations.Compose
          transforms:
            - *spatial_transforms
            - *post_transforms
        download: false

    criterion:
      _key_value: true

      content_loss:
        _target_: L1Loss  # L1Loss, MSELoss

      perceptual_loss:
        _target_: esrgan.PerceptualLoss
        layers:
          conv5_4: 1.0

      adversarial_generator_loss:
        _target_: &adversarial_criterion esrgan.RelativisticAdversarialLoss
        mode: generator
      adversarial_discriminator_loss:
        _target_: *adversarial_criterion
        mode: discriminator

    optimizer:
      _key_value: true

      generator_optimizer:
        _target_: AdamW
        lr_linear_scaling:
          lr: 0.00003
          base_batch_size: *base_batch_size
        weight_decay: 0.0
        _model: *generator_model

      discriminator_optimizer:
        _target_: AdamW
        lr_linear_scaling:
          lr: 0.0001
          base_batch_size: *base_batch_size
        weight_decay: 0.0
        _model: *discriminator_model

    scheduler:
      _key_value: true

      generator_scheduler:
        _target_: MultiStepLR
        milestones: [16, 24, 32]
        gamma: 0.5
        _optimizer: generator_optimizer

      discriminator_scheduler:
        _target_: MultiStepLR
        milestones: [8, 16, 24, 32]
        gamma: 0.5
        _optimizer: discriminator_optimizer

    callbacks:
      # loader:
      #   _target_: CheckpointCallback
      #   load_on_stage_start:
      #     model: ./logs/esrgan_x4_128ps/supervised/checkpoints/last.pth

      psnr_metric:
        _target_: esrgan.PSNRCallback
        input_key: real_image
        target_key: fake_image
      ssim_metric:
        _target_: esrgan.SSIMCallback
        input_key: real_image
        target_key: fake_image

      loss_content:
        _target_: CriterionCallback
        input_key: real_image
        target_key: fake_image
        metric_key: loss_content
        criterion_key: content_loss
      loss_perceptual:
        _target_: CriterionCallback
        input_key: real_image
        target_key: fake_image
        metric_key: loss_perceptual
        criterion_key: perceptual_loss
      loss_adversarial_generator:
        _target_: CriterionCallback
        input_key: null
        input_key: g_fake_logits  # first argument of criterion is fake_logits
        target_key: g_real_logits  # second argument of criterion is real_logits
        metric_key: loss_adversarial_generator
        criterion_key: adversarial_generator_loss
      loss_generator:
        _target_: MetricAggregationCallback
        prefix: &generator_loss loss_generator
        metrics:
          loss_content: 0.01
          loss_perceptual: 1.0
          loss_adversarial_generator: 0.05
        mode: weighted_sum

      loss_discriminator:
        _target_: CriterionCallback
        input_key: d_fake_logits  # first argument of criterion is fake_logits
        target_key: d_real_logits  # second argument of criterion is real_logits
        metric_key: &discriminator_loss loss_discriminator
        criterion_key: adversarial_discriminator_loss

      optimizer_generator:
        _target_: OptimizerCallback
        metric_key: *generator_loss
        optimizer_key: generator_optimizer
        grad_clip_fn: *grad_clip_fn
        grad_clip_params: *grad_clip_params
      optimizer_discriminator:
        _target_: OptimizerCallback
        metric_key: *discriminator_loss
        optimizer_key: discriminator_optimizer
        grad_clip_fn: *grad_clip_fn
        grad_clip_params: *grad_clip_params

      scheduler_generator:
        _target_: SchedulerCallback
        scheduler_key: generator_scheduler
        loader_key: *valid_loader
        metric_key: *generator_loss
      scheduler_discriminator:
        _target_: SchedulerCallback
        scheduler_key: discriminator_scheduler
        loader_key: *valid_loader
        metric_key: *discriminator_loss
